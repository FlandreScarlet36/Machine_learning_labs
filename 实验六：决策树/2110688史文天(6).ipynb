{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒè¦æ±‚\n",
    "### æˆªæ­¢æ—¥æœŸï¼š12æœˆ15æ—¥\n",
    "ä½œä¸šçš„æäº¤æ ¼å¼å‚è€ƒä¹‹å‰çš„è¯´æ˜ï¼Œæäº¤åˆ°18329300691@163.com\n",
    "### åŸºæœ¬è¦æ±‚\n",
    "a)\tåŸºäº Watermelon-train1æ•°æ®é›†ï¼ˆåªæœ‰ç¦»æ•£å±æ€§ï¼‰ï¼Œæ„é€ ID3å†³ç­–æ ‘ï¼›\n",
    "b)\tåŸºäºæ„é€ çš„ ID3 å†³ç­–æ ‘ï¼Œå¯¹æ•°æ®é›† Watermelon-test1è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å¯¼å…¥æ‰€éœ€çš„åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å¯¼å…¥æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetData_watermelon():\n",
    "    path = \"Watermelon-test1.csv\"\n",
    "    data = pd.read_csv(path, header=None, names=[\"è‰²æ³½\", \"æ ¹è’‚\",\"æ•²å£°\",\"çº¹ç†\",\"label\"], encoding='gbk')\n",
    "    clos = data.shape[1]  # è·å–åˆ—æ•°\n",
    "    all_data = data.iloc[:, 0:clos]\n",
    "    all_data = np.delete(np.array(all_data), 0, axis=0)  # åˆ é™¤é¦–è¡Œ\n",
    "    labels = data.columns.tolist()\n",
    "    labels.pop()\n",
    "    trainDataSet = np.array(all_data)  # é€‰å–äº†ä¸€éƒ¨åˆ†ä½œä¸ºè®­ç»ƒé›†\n",
    "    # å¾—åˆ°å‰ªææ•°æ®é›†\n",
    "    path = \"Watermelon-train1.csv\"\n",
    "    data = pd.read_csv(path, header=None, names=[\"è‰²æ³½\", \"æ ¹è’‚\",\"æ•²å£°\",\"çº¹ç†\",\"label\"], encoding='gbk')\n",
    "    clos = data.shape[1]  # è·å–åˆ—æ•°\n",
    "    new_data = data.iloc[:, 0:clos]\n",
    "    new_data = np.delete(np.array(all_data), 0, axis=0)  # åˆ é™¤é¦–è¡Œ\n",
    "    labels = data.columns.tolist()\n",
    "    labels.pop()\n",
    "    pruneDataSet = np.array(new_data)  # å¾—åˆ°è®­ç»ƒæ•°æ®é›†\n",
    " \n",
    "    return trainDataSet, pruneDataSet, np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### è®¡ç®—æ•°æ®é›†ä¿¡æ¯ç†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_entropy(dataset):\n",
    "    classLabel = dataset[:, -1] # æ ‡ç­¾\n",
    "    labelCount = {}\n",
    "    for i in range(classLabel.size):\n",
    "        label = classLabel[i]\n",
    "        labelCount[label] = labelCount.get(label, 0) + 1\n",
    "    # ç†µå€¼(ç¬¬ä¸€æ­¥)\n",
    "    cnt = 0\n",
    "    for k, v in labelCount.items():\n",
    "        cnt += -v / classLabel.size * np.log2(v / classLabel.size)\n",
    "    return cnt\n",
    " \n",
    "    # æ¥ä¸‹æ¥åˆ‡åˆ†,ç„¶åç®—æœ€ä¼˜å±æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ ¹æ®ç»™å®šçš„ç‰¹å¾ç´¢å¼•åˆ†å‰²æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataset, featureIndex):\n",
    "    subdataset = []\n",
    "    featureValues = dataset[:, featureIndex]\n",
    "    featureSet = list(set(featureValues))\n",
    "    for i in range(len(featureSet)):\n",
    "        newset = []\n",
    "        for j in range(dataset.shape[0]):\n",
    "            if featureSet[i] == featureValues[j]:\n",
    "                newset.append(dataset[j, :])\n",
    "        newset = np.delete(newset, featureIndex, axis=1)\n",
    "        subdataset.append(np.array(newset))\n",
    "    return subdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ ¹æ®ç»™å®šçš„ç‰¹å¾ç´¢å¼•å’Œå€¼åˆ†å‰²æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSetByValue(dataset, featureIndex, value):\n",
    "    subdataset = []\n",
    "    for example in dataset:\n",
    "        if example[featureIndex] == value:\n",
    "            subdataset.append(example)\n",
    "    if not subdataset:\n",
    "        return subdataset\n",
    "    return np.delete(subdataset, featureIndex, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é€‰æ‹©æœ€ä½³ç‰¹å¾ï¼Œä½¿ç”¨ä¿¡æ¯å¢ç›Šåº¦é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeature(dataset, labels):\n",
    "    featureNum = labels.size\n",
    "    minEntropy, bestFeatureIndex = 1, None\n",
    "    n = dataset.shape[0]\n",
    "    for i in range(featureNum):\n",
    "        featureEntropy = 0\n",
    "        allSubDataSet = splitDataSet(dataset, i)\n",
    "        for subDataSet in allSubDataSet:\n",
    "            featureEntropy += subDataSet.shape[0] / n * dataset_entropy(subDataSet)\n",
    "        if minEntropy > featureEntropy:\n",
    "            minEntropy = featureEntropy\n",
    "            bestFeatureIndex = i\n",
    "    return bestFeatureIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ„å»ºå†³ç­–æ ‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'æ ¹è’‚': {'ç¨èœ·': {'æ•²å£°': {'æµŠå“': 'å¦', 'æ²‰é—·': {'çº¹ç†': {'ç¨ç³Š': 'å¦', 'æ¸…æ™°': 'æ˜¯'}}}}, 'ç¡¬æŒº': 'å¦', 'èœ·ç¼©': 'æ˜¯'}}\n"
     ]
    }
   ],
   "source": [
    "def mayorClass(classList):\n",
    "    # è¿”å›ç±»åˆ«åˆ—è¡¨ä¸­å‡ºç°æœ€å¤šçš„ç±»åˆ«\n",
    "    labelCount = {}\n",
    "    for i in range(classList.size):\n",
    "        label = classList[i]\n",
    "        labelCount[label] = labelCount.get(label, 0) + 1\n",
    "    sortedLabel = sorted(labelCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedLabel[0][0]\n",
    "\n",
    "def createID3(dataset, labels):\n",
    "    # åˆ›å»ºID3å†³ç­–æ ‘\n",
    "    classList = dataset[:, -1]\n",
    "    if len(set(dataset[:, -1])) == 1:\n",
    "        return dataset[:, -1][0]\n",
    "    if labels.size == 0 or len(dataset[0]) == 1:\n",
    "        return mayorClass(classList)\n",
    "    bestFeatureIndex = chooseBestFeature(dataset, labels)\n",
    "    bestFeature = labels[bestFeatureIndex]\n",
    "    dtree = {bestFeature: {}}\n",
    "    featureList = dataset[:, bestFeatureIndex]\n",
    "    featureValues = set(featureList)\n",
    "    for value in featureValues:\n",
    "        subdataset = splitDataSetByValue(dataset, bestFeatureIndex, value)\n",
    "        sublabels = np.delete(labels, bestFeatureIndex)\n",
    "        dtree[bestFeature][value] = createID3(subdataset, sublabels)\n",
    "    return dtree\n",
    "\n",
    "def predict_class(inputTree, featLabels, testVec):\n",
    "    # ä½¿ç”¨è®­ç»ƒå¥½çš„å†³ç­–æ ‘è¿›è¡Œé¢„æµ‹\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    classlabel = None\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == int(key):\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classlabel = predict_class(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classlabel = secondDict[key]\n",
    "    return classlabel\n",
    "\n",
    "dataset, prunedata, labels = GetData_watermelon()\n",
    "mytree = createID3(dataset, labels)\n",
    "print(mytree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸­çº§è¦æ±‚\n",
    "a)  å¯¹æ•°æ®é›†Watermelon-train2ï¼Œæ„é€ C4.5æˆ–è€…CARTå†³ç­–æ ‘ï¼Œè¦æ±‚å¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ï¼›\n",
    "b)\tå¯¹æµ‹è¯•é›†Watermelon-test2è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'æ ¹è’‚': {'ç¨èœ·': {'æ•²å£°': {'æµŠå“': 'å¦', 'æ²‰é—·': {'çº¹ç†': {'ç¨ç³Š': 'å¦', 'æ¸…æ™°': 'æ˜¯'}}}}, 'ç¡¬æŒº': 'å¦', 'èœ·ç¼©': 'æ˜¯'}}\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—åŸºå°¼ç³»æ•°\n",
    "def dataset_gini(dataset): \n",
    "    classLabel = dataset[:, -1]\n",
    "    labelCount = {}\n",
    "    for i in range(classLabel.size):\n",
    "        label = classLabel[i]\n",
    "        labelCount[label] = labelCount.get(label, 0) + 1\n",
    "    Gini = 1.0\n",
    "    for k, v in labelCount.items():\n",
    "        Gini -= float(v / classLabel.size) * float(v / classLabel.size)\n",
    "    return Gini\n",
    "\n",
    "\n",
    "def chooseBestGiniFeature(dataset, labels):\n",
    "    featureNum = labels.size\n",
    "    minEntropy, bestFeatureIndex = 1, None\n",
    "    n = dataset.shape[0]\n",
    "    for i in range(featureNum):\n",
    "        featureEntropy = 0\n",
    "        allSubDataSet = splitDataSet(dataset, i)\n",
    "        for subDataSet in allSubDataSet:\n",
    "            featureEntropy += subDataSet.shape[0] / n * dataset_gini(subDataSet)\n",
    "        if minEntropy > featureEntropy:\n",
    "            minEntropy = featureEntropy\n",
    "            bestFeatureIndex = i\n",
    "    return bestFeatureIndex\n",
    "\n",
    "def createCART(dataset, labels):\n",
    "    classList = dataset[:, -1]\n",
    "    if len(set(dataset[:, -1])) == 1:\n",
    "        return dataset[:, -1][0]\n",
    "    if labels.size == 0 or len(dataset[0]) == 1:\n",
    "        return mayorClass(classList)\n",
    "    bestFeatureIndex = chooseBestGiniFeature(dataset, labels)\n",
    "    bestFeature = labels[bestFeatureIndex]\n",
    "    dtree = {bestFeature: {}}\n",
    "    featureList = dataset[:, bestFeatureIndex]\n",
    "    featureValues = set(featureList)\n",
    "    for value in featureValues:\n",
    "        subdataset = splitDataSetByValue(dataset, bestFeatureIndex, value)\n",
    "        sublabels = np.delete(labels, bestFeatureIndex)\n",
    "        dtree[bestFeature][value] = createCART(subdataset, sublabels)\n",
    "    return dtree\n",
    "\n",
    "CARTtree = createCART(dataset, labels)\n",
    "print(CARTtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é«˜çº§è¦æ±‚\n",
    "ä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼Œè§‚å¯Ÿæµ‹è¯•é›†åˆçš„åˆ†ç±»ç²¾åº¦æ˜¯å¦æœ‰æå‡ï¼Œç»™å‡ºåˆ†æè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cntAccNums(dataSet, pruneSet):\n",
    "    nodeClass = mayorClass(dataSet[:, -1])\n",
    "    rightCnt = 0\n",
    "    for vect in pruneSet:\n",
    "        if vect[-1] == nodeClass:\n",
    "            rightCnt += 1\n",
    "    return rightCnt\n",
    " \n",
    "def prePruning(dataSet, pruneSet, labels):\n",
    " \n",
    "    classList = dataSet[:, -1]\n",
    " \n",
    "    if len(set(classList)) == 1:\n",
    "        return classList[0]\n",
    " \n",
    "    if len(dataSet[0]) == 1:\n",
    "        return mayorClass(classList)\n",
    " \n",
    "    # è·å–æœ€å¥½ç‰¹å¾\n",
    "    bestFeat = chooseBestGiniFeature(dataSet, labels) # âˆš\n",
    "    bestFeatLabel = labels[bestFeat] # è·å–ç‰¹å¾åç§°\n",
    "    sublabels = np.delete(labels, bestFeat) # ä»ç‰¹å¾ååˆ—è¡¨åˆ é™¤\n",
    "    # è®¡ç®—åˆå§‹æ­£ç¡®ç‡\n",
    "    baseRightNums = cntAccNums(dataSet, pruneSet)\n",
    "    # å¾—åˆ°æœ€å¥½åˆ’åˆ†å±æ€§å–å€¼\n",
    "    featureList = dataSet[:, bestFeat]  # æœ€ä½³çš„ç‰¹å¾åˆ—ä¹Ÿé€‰å‡ºæ¥äº†\n",
    "    features = set(featureList) # å–å‡ºç‰¹å¾ä¸‹çš„å±æ€§é›†åˆ\n",
    "    # è®¡ç®—å°è¯•åˆ’åˆ†èŠ‚ç‚¹æ—¶çš„æ­£ç¡®ç‡\n",
    "    splitRightNums = 0.0\n",
    "    for value in features: # éå†æ¯ä¸€ä¸ªå±æ€§\n",
    "        # æ¯ä¸ªå±æ€§å–å€¼å¾—åˆ°çš„å­é›†\n",
    "        subDataSet = splitDataSetByValue(dataSet, bestFeat, value)\n",
    "        if len(subDataSet) != 0:\n",
    "            # æŠŠç”¨æ¥å‰ªæçš„å­é›†ä¹ŸæŒ‰ç…§ç›¸åº”å±æ€§å€¼åˆ’åˆ†ä¸‹å»\n",
    "            subPruneSet = splitDataSetByValue(pruneSet, bestFeat, value)\n",
    "            # if value == \"å‡¹é™·\":\n",
    "            #     print(subPruneSet)\n",
    "            splitRightNums += cntAccNums(subDataSet, subPruneSet)\n",
    "    if baseRightNums < splitRightNums:  # å¦‚æœä¸åˆ’åˆ†çš„æ­£ç¡®ç‚¹æ•°å°‘äºå°è¯•åˆ’åˆ†çš„ç‚¹æ•°ï¼Œåˆ™ç»§ç»­åˆ’åˆ†ã€‚\n",
    "        myTree = {bestFeatLabel: {}}\n",
    "    else:\n",
    "        return mayorClass(dataSet[:, -1])  # å¦åˆ™ï¼Œè¿”å›ä¸åˆ’åˆ†æ—¶æŠ•ç¥¨å¾—åˆ°çš„ç±»\n",
    " \n",
    "    # ä»¥ä¸‹ä»£ç å’Œä¸é¢„å‰ªæçš„ä»£ç å¤§è‡´ç›¸åŒï¼Œä¸€ç‚¹ä¸åŒåœ¨äºæ¯æ¬¡æµ‹è¯•é›†ä¹Ÿè¦å‚ä¸åˆ’åˆ†ã€‚\n",
    "    for value in features:\n",
    "        subDataSet = splitDataSetByValue(dataSet, bestFeat, value)\n",
    "        subPruneSet = splitDataSetByValue(pruneSet, bestFeat, value)\n",
    "        if len(subDataSet) != 0:\n",
    "            myTree[bestFeatLabel][value] = prePruning(subDataSet, subPruneSet, sublabels)\n",
    "        else:\n",
    "            # è®¡ç®—Dä¸­æ ·æœ¬æœ€å¤šçš„ç±»\n",
    "            myTree[bestFeatLabel][value] = mayorClass(classList)\n",
    "    return myTree\n",
    " \n",
    "def postPruning(dataSet, pruneSet, labels):\n",
    " \n",
    "    classList = dataSet[:, -1]\n",
    "    # å¦‚æœåŸºå°¼æŒ‡æ•°ä¸º0ï¼Œå³Dä¸­æ ·æœ¬å…¨å±äºåŒä¸€ç±»åˆ«ï¼Œè¿”å›\n",
    "    if len(set(classList)) == 1:\n",
    "        return classList[0]\n",
    "    # å±æ€§å€¼ä¸ºç©ºï¼Œåªå‰©ä¸‹ç±»æ ‡ç­¾\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return mayorClass(classList)\n",
    " \n",
    "    # å¾—åˆ°å¢ç›Šæœ€å¤§åˆ’åˆ†çš„å±æ€§ã€å€¼\n",
    "    bestFeat = chooseBestFeature(dataSet, labels)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel: {}}  # åˆ›å»ºå­—å…¸ï¼Œå³æ ‘çš„èŠ‚ç‚¹ã€‚\n",
    "    # ç”Ÿæˆå­æ ‘çš„æ—¶å€™è¦å°†å·²éå†çš„å±æ€§åˆ å»ã€‚æ•°å€¼å‹ä¸è¦åˆ é™¤ã€‚\n",
    "    sublabels = np.delete(labels, bestFeat)\n",
    "    featureList = dataSet[:, bestFeat]  # æœ€ä½³çš„ç‰¹å¾åˆ—ä¹Ÿé€‰å‡ºæ¥äº†\n",
    "    uniqueVals = set(featureList) # å–å‡ºç‰¹å¾ä¸‹çš„å±æ€§é›†åˆ\n",
    "    for value in uniqueVals:  # æ ‡ç§°å‹çš„å±æ€§å€¼æœ‰å‡ ç§ï¼Œå°±è¦å‡ ä¸ªå­æ ‘ã€‚\n",
    "        # Pythonä¸­åˆ—è¡¨ä½œä¸ºå‚æ•°ç±»å‹æ—¶ï¼Œæ˜¯æŒ‰ç…§å¼•ç”¨ä¼ é€’çš„ï¼Œè¦ä¿è¯åŒä¸€èŠ‚ç‚¹çš„å­èŠ‚ç‚¹èƒ½æœ‰ç›¸åŒçš„å‚æ•°ã€‚\n",
    "        subPrune = splitDataSetByValue(pruneSet, bestFeat, value)\n",
    "        subDataSet = splitDataSetByValue(dataSet, bestFeat, value)\n",
    "        if len(subDataSet) != 0:\n",
    "            myTree[bestFeatLabel][value] = postPruning(subDataSet, subPrune, sublabels)\n",
    "        else:\n",
    "            # è®¡ç®—Dä¸­æ ·æœ¬æœ€å¤šçš„ç±»\n",
    "            myTree[bestFeatLabel][value] = mayorClass(classList)\n",
    " \n",
    "    # åå‰ªæï¼Œå¦‚æœåˆ°è¾¾å¶å­èŠ‚ç‚¹ï¼Œå°è¯•å‰ªæã€‚\n",
    "    # è®¡ç®—æœªå‰ªææ—¶ï¼Œæµ‹è¯•é›†çš„æ­£ç¡®æ•°\n",
    "    numNoPrune = 0.0\n",
    "    for value in uniqueVals:\n",
    "        subDataSet = splitDataSetByValue(dataSet, bestFeat, value)\n",
    "        if len(subDataSet) != 0:\n",
    "            subPrune = splitDataSetByValue(pruneSet, bestFeat, value)\n",
    "            numNoPrune += cntAccNums(subDataSet, subPrune)\n",
    "    # è®¡ç®—å‰ªæåï¼Œæµ‹è¯•é›†æ­£ç¡®æ•°\n",
    "    numPrune = cntAccNums(dataSet, pruneSet)\n",
    "    # æ¯”è¾ƒå†³å®šæ˜¯å¦å‰ªæ, å¦‚æœå‰ªæåè¯¥èŠ‚ç‚¹ä¸Šæµ‹è¯•é›†çš„æ­£ç¡®æ•°å˜å¤šäº†ï¼Œåˆ™å‰ªæã€‚\n",
    "    if numNoPrune < numPrune:\n",
    "        return mayorClass(dataSet[:, -1])  # ç›´æ¥è¿”å›èŠ‚ç‚¹ä¸Šè®­ç»ƒæ•°æ®çš„å¤šæ•°ç±»ä¸ºèŠ‚ç‚¹ç±»ã€‚\n",
    " \n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'æ ¹è’‚': {'ç¨èœ·': 'å¦', 'ç¡¬æŒº': 'å¦', 'èœ·ç¼©': 'æ˜¯'}}\n",
      "{'æ ¹è’‚': {'ç¨èœ·': {'æ•²å£°': {'æµŠå“': 'å¦', 'æ²‰é—·': {'çº¹ç†': {'ç¨ç³Š': 'å¦', 'æ¸…æ™°': 'æ˜¯'}}}}, 'ç¡¬æŒº': 'å¦', 'èœ·ç¼©': 'æ˜¯'}}\n"
     ]
    }
   ],
   "source": [
    "preTree = prePruning(dataset, prunedata, labels)\n",
    "print(preTree)\n",
    "\n",
    "postTree = postPruning(dataset, prunedata, labels)\n",
    "print(postTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»€ä¹ˆæ˜¯å†³ç­–æ ‘\n",
    "<img src=\"https://s2.loli.net/2022/10/23/yTpSLmgFWOh4Y5d.png\" style=\"zoom:66%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–æ ‘çš„åˆ’åˆ†\n",
    "- å†³ç­–æ ‘ä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼š\n",
    "\tID3ï¼ŒC4.5å’ŒCARTï¼Œå®ƒä»¬åˆ†åˆ«å¯¹åº”çš„**ç‰¹å¾é€‰æ‹©å‡†åˆ™**æ˜¯ä¿¡æ¯å¢ç›Šï¼ˆID3ï¼‰ï¼Œä¿¡æ¯å¢ç›Šæ¯”ï¼ˆC4.5ï¼‰å’ŒåŸºå°¼æŒ‡æ•°ï¼ˆCARTï¼‰ã€‚\n",
    "\tå®ƒä»¬å†³å®šå½“å‰é€‰æ‹©å“ªä¸ªç‰¹å¾è¿›è¡Œæ•°æ®åˆ’åˆ†ï¼Œä½¿å¾—æ ·æœ¬åœ¨å½“ä¸‹èƒ½å¤Ÿè¢«æœ€å¤§ç¨‹åº¦çš„åˆ’åˆ†ã€‚\n",
    "- å¯¹äºç¦»æ•£å˜é‡ï¼Œé€‰å®š**å±æ€§**åˆ†ç±»å³å¯ï¼›\n",
    "- å¯¹äºè¿ç»­å˜é‡ï¼Œéœ€è¦é€‰å®š**åˆ’åˆ†ç‚¹**ã€‚\n",
    "- CARTå’ŒC4.5æ”¯æŒæ•°æ®ç‰¹å¾ä¸º**è¿ç»­åˆ†å¸ƒ**æ—¶çš„å¤„ç†ï¼Œèƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†ï¼Œä¸»è¦é€šè¿‡äºŒå…ƒåˆ‡åˆ†çš„æ–¹å¼æ¥å¤„ç†è¿ç»­å‹å˜é‡ï¼Œè¿™ä¸ªåˆ†è£‚ç‚¹çš„é€‰æ‹©åŸåˆ™æ˜¯ä½¿å¾—åˆ’åˆ†åçš„å­æ ‘ä¸­çš„â€œæ··ä¹±ç¨‹åº¦â€é™ä½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3ç®—æ³•\n",
    "- ID3ç®—æ³•çš„æ ¸â¼¼æ€æƒ³åº”ç”¨ä¿¡æ¯å¢ç›Šå‡†åˆ™ä½œä¸ºæ ‡å‡†,ä»‹ç»ä¿¡æ¯å¢ç›Šä¹‹å‰é¦–å…ˆä»‹ç»ä¸€ä¸‹ä¿¡æ¯ç†µå’Œæ¡ä»¶ç†µï¼š \n",
    "- ç†µï¼ˆentropyï¼‰æ¦‚å¿µï¼š\n",
    "\t    1948å¹´ï¼Œé¦™å†œæå‡ºäº†â€œä¿¡æ¯ç†µâ€çš„æ¦‚å¿µã€‚åœ¨ä¿¡æ¯è®ºä¸æ¦‚ç‡ç»Ÿè®¡ä¸­ï¼Œç†µæ˜¯è¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šæ€§çš„é‡ã€‚Xæ˜¯â¼€ä¸ªå–å€¼ä¸ºæœ‰é™ä¸ªçš„ç¦»æ•£éšæœºå˜é‡ï¼Œ\n",
    "$$ H(X)=-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log p\\left(x_{i}\\right)$$ \n",
    "$ğ»(ğ‘‹)$å°±è¢«ç§°ä½œéšæœºå˜é‡ğ‘‹çš„ç†µï¼Œå®ƒè¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šçš„åº¦é‡ã€‚ç†µå–å€¼è¶Šå¤§ï¼Œéšæœºå˜é‡ä¸ç¡®å®šæ€§è¶Šå¤§ã€‚å½“éšæœºå˜é‡ä¸ºå‡åŒ€åˆ†å¸ƒæ—¶ï¼Œç†µæœ€å¤§ã€‚å½“æŸä¸€çŠ¶æ€æ¦‚ç‡å–å€¼ä¸º1æ—¶ï¼Œç†µçš„å€¼ä¸ºé›¶ã€‚\n",
    "\n",
    "### ID3ç®—æ³•-æ¡ä»¶ç†µå’Œä¿¡æ¯å¢ç›Š\n",
    "- æ¡ä»¶ç†µ $ğ»(ğ‘Œâˆ£ğ‘‹)$ ï¼š\n",
    "\tè¡¨ç¤ºåœ¨å·²çŸ¥éšæœºå˜é‡ğ‘‹çš„æ¡ä»¶ä¸‹éšæœºå˜é‡ğ‘Œçš„ä¸ç¡®å®šæ€§ï¼Œå®šä¹‰ä¸ºç»™å®šğ‘‹æ¡ä»¶ä¸‹ğ‘Œçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç†µå¯¹ğ‘‹çš„æ•°å­¦æœŸæœ›:\n",
    "$$H(Y \\mid X)=\\sum_{x} p(x) H(Y \\mid X=x) =-\\sum_{x} p(x) \\sum_{y} p(y \\mid x) \\log p(y \\mid x)$$\n",
    "\n",
    "- ç‰¹å¾ğ´å¯¹æ•°æ®é›†ğ·çš„ä¿¡æ¯å¢ç›Šå°±æ˜¯ç†µ$ğ»(ğ·)$ä¸æ¡ä»¶ç†µ$ğ»(ğ·|ğ´)$ä¹‹å·®:\n",
    "$$ğ»(ğ·)âˆ’ğ»(ğ·âˆ£ğ´)$$\n",
    "\n",
    "\tè¡¨ç¤ºå·²çŸ¥ç‰¹å¾ğ´çš„ä¿¡æ¯è€Œä½¿å¾—æ•°æ®é›†ğ·çš„ä¿¡æ¯ä¸ç¡®å®šå‡å°‘çš„ç¨‹åº¦ã€‚ä¿¡æ¯å¢ç›Šè¶Šå¤§çš„ç‰¹å¾ä»£è¡¨å…¶å…·æœ‰æ›´å¼ºçš„åˆ†ç±»èƒ½åŠ›ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±è¦**é€‰æ‹©èƒ½å¤Ÿä½¿æ•°æ®çš„ä¸ç¡®å®šç¨‹åº¦å‡å°‘æœ€å¤šçš„ç‰¹å¾**ï¼Œä¹Ÿå°±æ˜¯ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ã€‚\n",
    "\n",
    "### ID3ç®—æ³•-åœæ­¢æ¡ä»¶\n",
    "- å†³ç­–æ ‘çš„ç”Ÿæˆ:\n",
    "\n",
    "\tä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºåˆ’åˆ†è¯¥èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œæ ¹æ®è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼å»ºç«‹å­èŠ‚ç‚¹ï¼›\n",
    "\tåœ¨å¯¹å­èŠ‚ç‚¹é€’å½’åœ°è°ƒç”¨ä»¥ä¸Šæ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ï¼Œå¾—åˆ°â¼€ä¸ªå†³ç­–æ ‘ã€‚\n",
    "    \n",
    "    \n",
    "- è¿­ä»£åœæ­¢æ¡ä»¶ï¼š\n",
    "  1. å½“å‰ç»“ç‚¹æ‰€æœ‰æ ·æœ¬éƒ½å±äºåŒâ¼€ç±»åˆ«ï¼›\n",
    "  2. å½“å‰ç»“ç‚¹çš„æ‰€æœ‰å±æ€§å€¼éƒ½ç›¸åŒï¼Œæ²¡æœ‰å‰©ä½™å±æ€§å¯ç”¨æ¥è¿›ä¸€æ­¥åˆ’åˆ†æ ·æœ¬ï¼›\n",
    "  3. è¾¾åˆ°æœ€å¤§æ ‘æ·±ï¼›\n",
    "  4. è¾¾åˆ°å¶å­ç»“ç‚¹çš„æœ€å°æ ·æœ¬æ•°ï¼›\n",
    "\n",
    "### ID3ç®—æ³•ä¸¾ä¾‹\n",
    "\n",
    "<img src=\"https://s2.loli.net/2022/10/23/p7gSQeYGnoBCd2i.png\" style=\"zoom:64%\" />\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\operatorname{Info}^{\\text {In }}(D)=-\\frac{9}{14} \\log _{2}\\left(\\frac{9}{14}\\right)-\\frac{5}{14} \\log _{2}\\left(\\frac{5}{14}\\right)=0.940 \\\\\n",
    "\\operatorname{Infoage~}(D)=\\frac{5}{14} \\times\\left(-\\frac{2}{5} \\times \\log _{2} \\frac{2}{5}-\\frac{3}{5} \\times \\log _{2} \\frac{3}{5}\\right)+\\frac{4}{14} \\times\\left(-\\frac{4}{4} \\times \\log _{2} \\frac{4}{4}-\\frac{0}{4} \\times \\log _{2} \\frac{0}{4}\\right) \n",
    "+\\frac{5}{14} \\times\\left(-\\frac{2}{5} \\times \\log _{2} \\frac{2}{5}-\\frac{3}{5} \\times \\log _{2} \\frac{3}{5}\\right)=0.694 \\\\\n",
    "\\text { Gain }(\\text { age })=\\operatorname{Info}(D)-\\operatorname{InfO}_{\\text {age }}(D) =0.940-0.694=0.246\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<img src=\"https://s2.loli.net/2022/10/23/1zAnHWKRgQ9FaJV.png\" style=\"zoom:72%\" />\n",
    "ç±»ä¼¼åœ°ï¼Œ\n",
    "Gain(income)=0.029    \n",
    "Gain(student)=0.151    \n",
    "Gain(credit_rating)=0.048\n",
    "\n",
    "æ‰€ä»¥ï¼Œé€‰æ‹©ageä½œä¸ºç¬¬ä¸€ä¸ªæ ¹èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5ç®—æ³•\n",
    "- C4.5ç®—æ³•ä¸ID3ç®—æ³•ç›¸ä¼¼ï¼Œå…¶å¯¹ID3ç®—æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚\n",
    "- ä¿¡æ¯å¢ç›Šä½œä¸ºåˆ’åˆ†å‡†åˆ™å­˜åœ¨çš„é—®é¢˜ï¼š\n",
    "\n",
    "     ä¿¡æ¯å¢ç›Šåå‘äºé€‰æ‹©å–å€¼è¾ƒå¤šçš„ç‰¹å¾è¿›è¡Œåˆ’åˆ†ã€‚â½å¦‚å­¦å·è¿™ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªå­¦ç”Ÿéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„å­¦å·ï¼Œå¦‚æœæ ¹æ®å­¦å·å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ï¼Œåˆ™æ¯ä¸ªå­¦ç”Ÿéƒ½å±äºä¸åŒçš„ç±»åˆ«ï¼Œè¿™æ ·æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚è€ŒC4.5åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨**ä¿¡æ¯å¢ç›Šæ¯”**æ¥é€‰æ‹©ç‰¹å¾ï¼Œå¯ä»¥æ ¡æ­£è¿™ä¸ªé—®é¢˜ã€‚\n",
    "     \n",
    "- ç‰¹ç‚¹\n",
    "  - èƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†\n",
    "  - èƒ½å¤Ÿå¯¹ä¸å®Œæ•´æ•°æ®è¿›è¡Œå¤„ç†\n",
    "  - éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡çš„é¡ºåºæ‰«æå’Œæ’åº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARTç®—æ³•\n",
    "- ID3å’ŒC4.5è™½ç„¶åœ¨å¯¹è®­ç»ƒæ ·æœ¬é›†çš„å­¦ä¹ ä¸­å¯ä»¥å°½å¯èƒ½å¤šçš„æŒ–æ˜ä¿¡æ¯ï¼Œä½†å…¶ç”Ÿæˆçš„å†³ç­–æ ‘åˆ†æ”¯è¾ƒå¤§ï¼Œè§„æ¨¡è¾ƒå¤§ã€‚ä¸ºäº†ç®€åŒ–å†³ç­–æ ‘çš„è§„æ¨¡ï¼Œæé«˜ç”Ÿæˆå†³ç­–æ ‘çš„æ•ˆç‡ï¼Œå°±å‡ºç°äº†æ ¹æ®**åŸºå°¼æŒ‡æ•°**æ¥é€‰æ‹©çš„CARTï¼› \n",
    "- å¯¹äºç»™å®šçš„æ ·æœ¬é›†åˆ ï¼Œå…¶åŸºå°¼æŒ‡æ•°ä¸ºï¼š $$ {Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2} $$\n",
    "   å…¶ä¸­$ğ¶_ğ‘˜$æ˜¯ğ·ä¸­å±äºç¬¬ğ‘˜ç±»çš„æ ·æœ¬å­é›†ï¼ŒKæ˜¯ç±»çš„ä¸ªæ•°ã€‚\n",
    "- åŸºå°¼ç³»æ•°çš„æ€§è´¨ä¸ä¿¡æ¯ç†µä¸€æ ·ï¼š\n",
    "   åº¦é‡éšæœºå˜é‡çš„ä¸ç¡®å®šåº¦çš„å¤§å°ï¼›åŸºå°¼æŒ‡æ•°è¶Šâ¼©è¡¨ç¤ºæ•°æ®çš„çº¯åº¦è¶Šé«˜ï¼Œåä¹‹å…¶å€¼è¶Šå¤§ï¼Œæ ·æœ¬é›†åˆçš„ä¸ç¡®å®šæ€§ä¹Ÿå°±è¶Šå¤§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–æ ‘çš„å‰ªæ\n",
    "- å†³ç­–æ ‘å¾ˆå®¹æ˜“å‡ºç°**è¿‡æ‹Ÿåˆç°è±¡**ã€‚åŸå› åœ¨äºå­¦ä¹ æ—¶å®Œå…¨è€ƒè™‘çš„æ˜¯å¦‚ä½•æâ¾¼å¯¹è®­ç»ƒæ•°æ®çš„æ­£ç¡®åˆ†ç±»ä»â½½æ„å»ºå‡ºè¿‡äºå¤æ‚çš„å†³ç­–æ ‘ã€‚\n",
    "- è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ç§°ä¸º**å‰ªæ**ï¼Œå³å¯¹å·²ç”Ÿæˆçš„æ ‘è¿›è¡Œç®€åŒ–ã€‚å…·ä½“åœ°ï¼Œå°±æ˜¯ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šè£å‰ªæ‰â¼€äº›å­æ ‘æˆ–å¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶æ ¹èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä½œä¸ºæ–°çš„å¶èŠ‚ç‚¹ã€‚ \n",
    "- å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ (Pre-Pruning)** å’Œ **åå‰ªæ (Post-Pruning)**\n",
    "   - **é¢„å‰ªæ**ï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™**ææ—©çš„åœæ­¢æ ‘å¢é•¿**ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚ \n",
    "   - **åå‰ªæ**ï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹å**è‡ªåº•å‘ä¸Š**çš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
